# ADR-002: Стратегия кэширования для Prompt Configuration Service

## Статус
Предложено

## Контекст

При разработке Prompt Configuration Service необходимо решить вопрос отказоустойчивости системы LearnFlow при недоступности сервиса конфигурации промптов. Основная проблема заключается в том, что промпты содержат как статические плейсхолдеры (настройки пользователя из БД), так и динамические (контент экзамена, распознанный текст и т.д.).

### Ключевые требования:
1. **Качество важнее доступности** - недопустимо использовать устаревшие или неподходящие промпты
2. **Динамический контент** - промпты содержат данные, которые меняются при каждом запросе
3. **Отказоустойчивость** - система должна продолжать работу при временной недоступности сервиса конфигурации

### Проблема кэширования:
Если кэшировать полностью отрендеренные промпты (с подставленными значениями), то при следующем запросе с другим динамическим контентом мы получим устаревшие данные, что критически снизит качество генерации.

## Решение

Реализовать двухэтапную стратегию: MVP для быстрого запуска и Production-ready решение для долгосрочной эксплуатации.

### MVP версия (Фаза 1)

**Архитектура:**
- PromptConfigService рендерит полный промпт на своей стороне
- LearnFlow получает готовый промпт через API
- Отсутствие кэширования для обеспечения консистентности
- Retry механизм с экспоненциальной задержкой
- Fail-fast при недоступности сервиса

**API:**
```http
POST /api/v1/generate-prompt
{
    "user_id": 123,
    "node_name": "generating_content",
    "context": {
        "exam_content": "динамический контент..."
    }
}

Response: {
    "prompt": "Полностью отрендеренный промпт..."
}
```

**Клиент в LearnFlow:**
```python
class SimplePromptClient:
    async def get_prompt(self, user_id: int, node_name: str, context: dict):
        # Только retry, без кэша
        for attempt in range(3):
            try:
                return await self._fetch_from_service(user_id, node_name, context)
            except Exception as e:
                if attempt < 2:
                    await asyncio.sleep(0.5 * (attempt + 1))
                else:
                    raise WorkflowExecutionError("Service unavailable")
```

**Преимущества:**
- Простота реализации
- Гарантия актуальности данных
- Централизованная логика рендеринга

**Недостатки:**
- Single point of failure
- Отсутствие работы при недоступности сервиса

### Production версия (Фаза 2+)

**Архитектура:**
- PromptConfigService возвращает template + статические настройки отдельно
- LearnFlow кэширует template и настройки пользователя
- Рендеринг происходит на стороне LearnFlow
- Graceful degradation с устаревшим кэшем

**API:**
```http
POST /api/v1/prompt-data
{
    "user_id": 123,
    "node_name": "generating_content"
}

Response: {
    "template": "You are {{role}}. Analyze: {{exam_content}}",
    "user_placeholders": {
        "role": "expert",
        "style": "detailed"
    },
    "required_dynamic_placeholders": ["exam_content"],
    "cache_ttl": 3600
}
```

**PromptManager в LearnFlow:**
```python
class PromptManager:
    def __init__(self):
        self.cache = {}  # Кэш templates и настроек
        
    async def get_rendered_prompt(self, user_id, node_name, dynamic_context):
        # 1. Получаем данные (из кэша или сервиса)
        prompt_data = await self._get_prompt_data_with_cache(user_id, node_name)
        
        # 2. Рендерим локально с динамическим контекстом
        all_placeholders = {
            **prompt_data['user_placeholders'],
            **dynamic_context
        }
        
        template = Template(prompt_data['template'])
        return template.render(**all_placeholders)
```

**Преимущества:**
- Устойчивость к сбоям сервиса конфигурации
- Кэширование только статических данных
- Всегда актуальный динамический контент
- Возможность работы с устаревшим кэшем

**Недостатки:**
- Дублирование логики рендеринга
- Сложность реализации
- Необходимость синхронизации версий шаблонов

## Границы ответственности

### MVP версия:
- **PromptConfigService**: Хранение, управление и полный рендеринг промптов
- **LearnFlow**: Только вызов API и обработка ошибок

### Production версия:
- **PromptConfigService**: Хранение и управление шаблонами и настройками
- **LearnFlow**: Кэширование, рендеринг и fallback логика

## План миграции

### Фаза 1: MVP (Текущая разработка)
- Реализовать простой API с полным рендерингом
- Клиент без кэширования с retry механизмом
- Fail-fast при недоступности

### Фаза 2: Разделение API
- Добавить endpoint `/api/v1/prompt-data` 
- Возвращать template и placeholders отдельно
- Поддержка обратной совместимости

### Фаза 3: Локальный рендеринг
- Реализовать PromptManager в LearnFlow
- Добавить in-memory кэширование
- Feature flag для постепенного rollout

### Фаза 4: Оптимизации
- Batch API для прогрева кэша
- Persistent кэш (Redis/файловая система)
- Метрики и мониторинг cache hit rate

## Последствия

### Положительные:
- Быстрый запуск MVP с возможностью эволюции
- Четкий путь к production-ready решению
- Отсутствие over-engineering на старте
- Гарантия качества генерации

### Отрицательные:
- Необходимость рефакторинга при переходе к production
- Временная зависимость от доступности сервиса в MVP
- Усложнение архитектуры в production версии

## Альтернативы рассмотренные

1. **Fallback на статичные промпты** - отвергнуто из-за критического снижения качества
2. **Полное кэширование отрендеренных промптов** - отвергнуто из-за проблем с динамическим контентом
3. **Только production версия сразу** - отвергнуто из-за сложности и времени разработки

## Решение

Принять двухэтапную стратегию:
1. Начать с MVP версии без кэширования для быстрого запуска
2. Эволюционировать к production версии с разделенным API и локальным рендерингом

Это позволит быстро выпустить работающий продукт и собрать метрики для обоснования инвестиций в более сложную архитектуру.