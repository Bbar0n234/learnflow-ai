"""
–£–∑–µ–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤.
–ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –±–µ–∑ HITL: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ–¥–∏–Ω —Ä–∞–∑ –µ—Å–ª–∏ –Ω–µ—Ç.
"""

import base64
import logging
from typing import List
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langgraph.types import Command, interrupt

from ..core.state import ExamState
from .base import BaseWorkflowNode


logger = logging.getLogger(__name__)


def load_images_as_base64(image_paths: List[str]) -> List[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64 —Ñ–æ—Ä–º–∞—Ç.

    Args:
        image_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º

    Returns:
        –°–ø–∏—Å–æ–∫ base64 —Å—Ç—Ä–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    base64_images = []
    for image_path in image_paths:
        try:
            with open(image_path, "rb") as image_file:
                base64_string = base64.b64encode(image_file.read()).decode("utf-8")
                base64_images.append(base64_string)
                logger.info(f"Loaded image: {image_path}")
        except Exception as e:
            logger.error(f"Failed to load image {image_path}: {e}")

    return base64_images


class RecognitionNode(BaseWorkflowNode):
    """
    –£–∑–µ–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
    - –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤
    - –ü—Ä—è–º–æ–≥–æ –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ (–ø–µ—á–∞—Ç–Ω—ã–π –≤–∏–¥)
    - –í–∞–ª–∏–¥–∞—Ü–∏–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
    - –ü—Ä–æ–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ –∂–µ–ª–∞–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    
    MIN_TEXT_LENGTH = 50  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞

    def __init__(self):
        super().__init__(logger)
        self.model = self.create_model()

    def get_node_name(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º—è —É–∑–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return "recognition_handwritten"
    
    def _build_context_from_state(self, state) -> dict:
        """–°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è workflow"""
        return {
            # –£–∑–µ–ª recognition –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ state –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        }

    async def __call__(self, state: ExamState, config) -> Command:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —É–∑–ª–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.

        Args:
            state: –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º–∏ image_paths
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LangGraph

        Returns:
            Command —Å –ø–µ—Ä–µ—Ö–æ–¥–æ–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —É–∑–ª—É
        """
        thread_id = config["configurable"]["thread_id"]
        logger.info(f"Starting recognition processing for thread {thread_id}")

        # –°–ª—É—á–∞–π 1: –ï—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Ö
        if state.image_paths:
            logger.info(
                f"Found {len(state.image_paths)} images, processing recognition"
            )

            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                recognized_text = await self._process_images(state.image_paths, state, config)

                if recognized_text:
                    logger.info(
                        f"Successfully recognized text from images for thread {thread_id}"
                    )
                    return Command(
                        goto="synthesis_material",
                        update={"recognized_notes": recognized_text},
                    )
                else:
                    logger.warning(
                        f"Failed to recognize text from images for thread {thread_id}"
                    )
                    # –ü—Ä–∏ –æ—à–∏–±–∫–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ç–µ–∑
                    return Command(
                        goto="generating_questions",
                        update={
                            "recognized_notes": "",
                            "synthesized_material": state.generated_material
                        }
                    )

            except Exception as e:
                logger.error(f"Error processing images for thread {thread_id}: {e}")
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ç–µ–∑
                return Command(
                    goto="generating_questions",
                    update={
                        "recognized_notes": "",
                        "synthesized_material": state.generated_material
                    }
                )

        # –°–ª—É—á–∞–π 2: –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–æ–Ω—Å–ø–µ–∫—Ç—ã —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        logger.info(f"No images found for thread {thread_id}, requesting notes from user")

        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–æ–Ω—Å–ø–µ–∫—Ç—ã —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —Ç–µ–∫—Å—Ç)
        message_content = (
            "üì∏ –î–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –≤–∞—à–∏ –∫–æ–Ω—Å–ø–µ–∫—Ç—ã.\n\n"
            "–í–∞—Ä–∏–∞–Ω—Ç—ã –¥–µ–π—Å—Ç–≤–∏–π:\n"
            "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤\n"
            "‚Ä¢ –í—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç —É–∂–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö/–ø–µ—á–∞—Ç–Ω—ã—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤\n"
            "‚Ä¢ –ù–∞–ø–∏—à–∏—Ç–µ '–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å' –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –±–µ–∑ –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤"
        )

        # –î–µ–ª–∞–µ–º interrupt –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        interrupt_json = {"message": [message_content]}
        user_response = interrupt(interrupt_json)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ - –º–µ–Ω–µ–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–ø—É—Å–∫
        cleaned_text = user_response.strip()
        if len(cleaned_text) < self.MIN_TEXT_LENGTH:
            logger.info(f"Text too short ({len(cleaned_text)} chars), user wants to skip notes for thread {thread_id}")
            # –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
            return Command(
                goto="generating_questions",
                update={
                    "recognized_notes": "",
                    "synthesized_material": state.generated_material,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º generated_material –∫–∞–∫ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π
                },
            )
        
        # –¢–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –¥–ª–∏–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å–ø–µ–∫—Ç—ã
        logger.info(f"Received text notes ({len(cleaned_text)} chars) for thread {thread_id}, proceeding to synthesis")
        return Command(
            goto="synthesis_material",
            update={"recognized_notes": cleaned_text}
        )

    async def _process_images(self, image_paths: List[str], state: ExamState, config) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é GPT-4-vision.

        Args:
            image_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            state: –°–æ—Å—Ç–æ—è–Ω–∏–µ workflow
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LangGraph

        Returns:
            –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64
            base64_images = load_images_as_base64(image_paths)
            if not base64_images:
                logger.error("Failed to load any images for recognition")
                return ""

            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –æ—Ç —Å–µ—Ä–≤–∏—Å–∞
            system_content = await self.get_system_prompt(state, config)

            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è GPT-4-vision
            user_content = [
                {
                    "type": "text",
                    "text": "–í–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:",
                }
            ]

            for base64_img in base64_images:
                user_content.append(
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_img}"},
                    }
                )

            # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
            messages = [
                SystemMessage(content=system_content),
                HumanMessage(content=user_content),
            ]

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏
            response = await self.model.ainvoke(messages)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç (—É–±–∏—Ä–∞–µ–º —Å–µ–∫—Ü–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π)
            content = response.content
            if "[END OF REASONING]" in content:
                content = content.split("[END OF REASONING]")[1].strip()

            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤
            if self.security_guard and content:
                content = await self.validate_input(content)

            return content

        except Exception as e:
            logger.error(f"Error in image processing: {e}")
            return ""
